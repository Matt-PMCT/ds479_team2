# Record start time
start_time <- Sys.time()
message("Process started at: ", start_time)

# install / load libraries -----------------------------------------------
required_pkgs <- c(
  "tidyverse", "lubridate", "janitor", "timetk", "tidymodels", "modeltime", 
  "ranger", "xgboost", "scales", "ggplot2", "labeling", "furrr", "modeltime.resample",
  "tune", "yardstick", "fs"
)
missing_pkgs <- setdiff(required_pkgs, rownames(installed.packages()))
if (length(missing_pkgs)) 
  install.packages(missing_pkgs, repos = "https://cloud.r-project.org")
# Ensure they load in a reproducible order
invisible(lapply(required_pkgs, library, character.only = TRUE))

# Set seed for reproducibility
set.seed(123)

# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)

# Toggle development mode: TRUE for only 10 areas and simplified settings
development_mode <- FALSE

# Model & feature settings based on mode ---------------------------------
lag_spec <- list(
  value = 1:6,
  mort_rate = 0:2,
  temperature_2m_mean = 0:2,
  temperature_2m_max  = 0:2,
  temperature_2m_min  = 0:2,
  sunshine_duration   = 0:2,
  precipitation_sum   = 0:2,
  snowfall_sum        = 0:2
)
if (development_mode) {
  model_params <- list(trees = 100, tree_depth = 4, learn_rate = 0.1, sample_size = 0.5)
  fh_years     <- 1
  group_limit  <- 10
} else {
  model_params <- list(trees = 500, tree_depth = 6, learn_rate = 0.05, sample_size = 0.8)
  fh_years     <- 1
  group_limit  <- Inf
}


# 1. Load ALL monthly consent sub-series -----------------------------------
if (!exists("consents_all")) {
  message("Loading consents data...")
  path <- "./datasets/building_consents/Building_consents_by_territorial_authority_(Monthly)_trimmed.csv"
  consents_csv <- read_csv(path,
                           col_types = cols(period = col_character()),
                           show_col_types = FALSE
  ) %>% clean_names()
  consents_csv_2 <- consents_csv %>%
    transmute(
      territorial_authority = series_title_1,
      category              = series_title_2,
      # force exactly two decimals
      period_str = sprintf("%.2f", period),  
      value      = data_value
    ) %>%
    separate(period_str, into = c("year","month"), sep = "\\.", convert = TRUE)
  consents_csv_3 <- consents_csv_2 %>%
    mutate(date = make_date(year, month, 1)) %>%
    select(territorial_authority, category, date, value)
  
  
  # only load if not already in memory
  consents_all <- consents_csv_3
} else {
  message("Consents data already loaded.")
}


# 2. Load mortgage & weather (monthly) -------------------------------------
# only load if not already in memory
if (!exists("mortgage_monthly")) {
  message("Loading mortgage data...")
  mortgage_monthly <- read_csv(
    "./datasets/mortgage_rates/rbnz_gov_2005-2025_mortgage_rates_hb20.csv",
    skip = 4, show_col_types = FALSE
  ) %>%
    rename(date_label = `Series Id`) %>%
    transmute(
      date      = parse_date_time(date_label, "b Y") %>% floor_date("month"),
      mort_rate = as.numeric(MTGE.MBI.F)
    ) %>%
    drop_na()
} else {
  message("Mortgage data already loaded.")
}

# only load if not already in memory
if (!exists("weather_monthly")) {
  message("Loading weather data...")
  tmp_weather_fun <- function(f) {
    region <- f %>% basename() %>% str_remove_all("(weather-|\\.csv)") %>% str_replace_all("_"," ")
    read_csv(f, show_col_types = FALSE) %>%
      mutate(
        date                  = ymd(time) %>% floor_date("month"),
        territorial_authority = region
      ) %>%
      group_by(territorial_authority, date) %>%
      summarise(
        temperature_2m_mean  = mean(temperature_2m_mean,  na.rm = TRUE),
        temperature_2m_max   = mean(temperature_2m_max,   na.rm = TRUE),
        temperature_2m_min   = mean(temperature_2m_min,   na.rm = TRUE),
        sunshine_duration    = sum(sunshine_duration,     na.rm = TRUE),
        precipitation_sum    = sum(precipitation_sum,     na.rm = TRUE),
        snowfall_sum         = sum(snowfall_sum,          na.rm = TRUE),
        .groups = "drop"
      )
  }
  weather_files   <- list.files("./datasets/weather", pattern = "^weather-.*\\.csv$", full.names = TRUE)
  weather_monthly <- future_map_dfr(
    weather_files,
    tmp_weather_fun,
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
  )
} else {
  message("Weather data already loaded.")
}

# 3. Combine data ----------------------------------------------------------
# Only do this if not already in memory
if (!exists("data_monthly_all")) {
  message("Combining all data...")
  data_monthly_all <- consents_all %>%
    left_join(mortgage_monthly, by = "date") %>%
    left_join(weather_monthly,   by = c("territorial_authority","date")) %>%
    arrange(territorial_authority, category, date) %>%
    drop_na(mort_rate, temperature_2m_mean)
  # Convert date to Date type
  data_monthly_all <- data_monthly_all %>%
    mutate(date = as.Date(date))
} else {
  message("Data already combined.")
}

# 4. Feature engineering fn -----------------------------------------------
make_features <- function(df) {
  df %>%
    arrange(date) %>%
    tk_augment_lags(value,               .lags = lag_spec$value) %>%
    tk_augment_lags(mort_rate,           .lags = lag_spec$mort_rate) %>%
    tk_augment_lags(temperature_2m_mean, .lags = lag_spec$temperature_2m_mean) %>%
    tk_augment_lags(temperature_2m_max,  .lags = lag_spec$temperature_2m_max) %>%
    tk_augment_lags(temperature_2m_min,  .lags = lag_spec$temperature_2m_min) %>%
    tk_augment_lags(sunshine_duration,   .lags = lag_spec$sunshine_duration) %>%
    tk_augment_lags(precipitation_sum,   .lags = lag_spec$precipitation_sum) %>%
    tk_augment_lags(snowfall_sum,        .lags = lag_spec$snowfall_sum) %>%
    tk_augment_slidify(value, .period = 3, .f = mean, .names = "roll3") %>%
    mutate(
      year  = year(date),
      month = month(date),
      index = row_number()
    )
}

# 5. Model loop ------------------------------------------------------------
groups <- data_monthly_all %>% 
  distinct(territorial_authority, category) %>% 
  slice_head(n = group_limit)

all_cv_metrics <- future_pmap_dfr(
  list(groups$territorial_authority, groups$category),
  function(ta, cat) {
    df   <- data_monthly_all %>% 
      filter(territorial_authority == ta, category == cat)
    feat <- make_features(df)
    print(names(feat))
    # 1) build rolling‐window splits
    cv_splits <- time_series_cv(
      data       = feat,
      date_var   = date,
      initial    = "60 months",
      assess     = "12 months",
      skip       = "12 months",
      cumulative = FALSE
    )
    
    # 2) define recipe + model spec
    rec <- recipe(value ~ ., data = feat) %>%
      update_role(date, territorial_authority, category, new_role = "id") %>%
      step_timeseries_signature(date) %>%
      step_rm(territorial_authority, category, date, matches("iso_|\\.stamp")) %>%
      step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
      step_mutate(across(where(is.logical), ~ as.numeric(.x))) %>%
      step_zv(all_predictors()) %>%
      step_normalize(all_numeric_predictors())
    
    spec <- boost_tree(
      trees       = model_params$trees,
      tree_depth  = model_params$tree_depth,
      learn_rate  = model_params$learn_rate,
      sample_size = model_params$sample_size
    ) %>%
      set_engine("xgboost") %>%
      set_mode("regression")
    
    wf <- workflow() %>%
      add_recipe(rec) %>%
      add_model(spec)
    
    # 3) fit across all rolling windows
    resamples_fitted <- fit_resamples(
      wf,
      resamples = cv_splits,
      metrics   = metric_set(rmse, mae, rsq),
      control   = control_resamples(
        verbose   = TRUE,
        save_pred = TRUE
      )
    )
    
    # 4) collect & average the metrics per series
    cv_metrics <- resamples_fitted %>%
      collect_metrics() %>%                         # yields columns .metric, .estimator, mean, std_err, n
      filter(.metric %in% c("rmse", "mae", "rsq")) %>% 
      select(.metric, mean) %>%                     # keep only the metric name and its aggregated mean
      pivot_wider(
        names_from   = .metric, 
        values_from  = mean
      ) %>%
      rename(
        rmse_mean = rmse,
        mae_mean  = mae,
        rsq_mean  = rsq
      ) %>%
      mutate(
        territorial_authority = ta,
        category              = cat
      )
    
    return(cv_metrics)
  },
  .options  = furrr_options(seed = TRUE),
  .progress  = TRUE
)

print(all_cv_metrics)

# 6. Pure 2024 hold-out: train through 2023, predict & evaluate 2024 
# Loop over each (territorial_authority, category)
results <- future_pmap_dfr(
  list(groups$territorial_authority, groups$category),
  function(ta, cat) {
    
    # --- A) Prep & fit on full history (incl. 2024) ----------------------------
    df_full <- data_monthly_all %>%
      filter(territorial_authority == ta, category == cat)
    feat_full <- df_full
    wf <- workflow() %>%
      add_recipe(
        recipe(value ~ ., data = feat_full) %>%
          update_role(date, territorial_authority, category, new_role = "id") %>%
          step_timeseries_signature(date) %>%
          step_rm(territorial_authority, category, date, matches("iso_|\\.stamp")) %>%
          step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
          step_mutate(across(where(is.logical), ~ as.numeric(.x))) %>%
          step_zv(all_predictors()) %>%
          step_normalize(all_numeric_predictors())
      ) %>%
      add_model(
        boost_tree(
          trees       = model_params$trees,
          tree_depth  = model_params$tree_depth,
          learn_rate  = model_params$learn_rate,
          sample_size = model_params$sample_size
        ) %>%
          set_engine("xgboost") %>%
          set_mode("regression")
      ) %>%
      fit(feat_full)
    
    # --- B) In-sample 2024 validation -----------------------------------------
    df_2024   <- df_full %>%
      filter(date >= as.Date("2024-01-01") & date <= as.Date("2024-12-01"))
    feat_2024 <- df_2024
    
    preds_2024 <- predict(wf, new_data = feat_2024) %>%
      bind_cols(
        feat_2024 %>% 
          select(territorial_authority, category, date)
      ) %>%
      mutate(.pred = pmax(.pred, 0))

    
      return(preds_2024)
  },
  .options  = furrr_options(seed = TRUE),
  .progress  = TRUE
)

# Now `results` contains both 2024 validation metrics and 2025 forecasts.
# If you’d rather keep them in two tables:

validation_2024 <- results

# Write them out if you want:
write_csv(validation_2024, "./results/validation_2024.csv")


# 7. Plotting --------------------------------------------------------------
# 1) make sure the folder exists
dir_create("plots/2024_validation")

# 2) join to the true 2024 values
validation_full <- validation_2024 %>%
  left_join(
    data_monthly_all %>%
      filter(between(date, as.Date("2024-01-01"), as.Date("2024-12-01"))) %>%
      select(territorial_authority, category, date, actual = value),
    by = c("territorial_authority", "category", "date")
  )

# 3) for each (district, category), save three plots
validation_full %>%
  group_by(territorial_authority, category) %>%
  group_walk(~{
    df   <- .x
    ta   <- .y$territorial_authority
    catg <- .y$category
    
    # a) Time‐series: Actual vs Predicted
    p1 <- ggplot(df, aes(date)) +
      geom_line(aes(y = actual,   color = "Actual"),   size = 1) +
      geom_line(aes(y = .pred,    color = "Predicted"),size = 1) +
      labs(
        title = paste("2024 Actual vs Predicted —", ta, "/", catg),
        x     = "Date", y = "Value", color = ""
      ) +
      theme_minimal() +
      theme(legend.position = "bottom")
    
    ggsave(
      filename = paste0(
        "plots/2024_validation/ts_act_vs_pred_",
        str_replace_all(ta,"\\s+","_"), "_",
        str_replace_all(catg,"\\s+","_"), ".png"
      ),
      plot   = p1, width = 10, height = 6, bg = "white"
    )
    
    # b) Scatter: Predicted vs Actual
    p2 <- ggplot(df, aes(actual, .pred)) +
      geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
      geom_point(alpha = 0.7) +
      labs(
        title = paste("2024 Predicted vs Actual —", ta, "/", catg),
        x     = "Actual", y = "Predicted"
      ) +
      theme_minimal()
    
    ggsave(
      filename = paste0(
        "plots/2024_validation/scatter_",
        str_replace_all(ta,"\\s+","_"), "_",
        str_replace_all(catg,"\\s+","_"), ".png"
      ),
      plot   = p2, width = 6, height = 6, bg = "white"
    )
    
    # c) Histogram: Residuals
    df <- df %>% mutate(residual = .pred - actual)
    p3 <- ggplot(df, aes(residual)) +
      geom_histogram(bins = 20, alpha = 0.8) +
      labs(
        title = paste("2024 Residuals —", ta, "/", catg),
        x     = "Prediction − Actual", y = "Count"
      ) +
      theme_minimal()
    
    ggsave(
      filename = paste0(
        "plots/2024_validation/hist_resid_",
        str_replace_all(ta,"\\s+","_"), "_",
        str_replace_all(catg,"\\s+","_"), ".png"
      ),
      plot   = p3, width = 8, height = 6, bg = "white"
    )
  })